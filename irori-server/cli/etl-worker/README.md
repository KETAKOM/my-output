## 2000万件ETLパイプライン (Go×並列処理×RDS)
### シナリオ: IoTログのETL

実行用のコマンド
```
go run main.go -start_at "2025-10-01 00:00:00" -end_at "2025-10-02 00:00:00"
```

#### 要件
- 2000万件のデータをETLする基盤を実装する
- 1日1回深夜にETLを実行する
- 冪等性を担保する
- 期間を絞って実行を可能にする
- TODO: リトライ処理を実装する

#### 概要
- Golangの並列処理を利用したETL基盤のサンプル(RDB to RDB)
    - **過去に　API to RDB　なETL基盤を作った経験あり**
- 実データはdaily: 100万件ほどを目安とするが、サービスの拡大も考慮して2000万件ETL可能にする
- **30分ほどで2000万件ほどのデータがETL可能になることが目標**
- **チャンク分割/並列処理/バルクインサートを活用する**
- **IDレンジ分割によるOFFSET排除**
- **冪等性確保のUpsert設計**
- **1万件単位のバルク挿入 + トランザクション制御**
- EventBridgeでDaily: 1回、ECSタスクで起動させる
- 基本はtimestampeで直近の1日分を取得、再実行用に細かいstart_at: end_atを指定可能

- TODO: RDS Proxy対応
- TODO: エラー時のリトライ設計
- TODO: ECSタスク化

#### 技術選定理由
- Golangの並列処理を実装したかったので、言語はGo
- 実運用も考慮してEventBridgeからECSタスクを起動して動かすイメージ
- ローカル環境で簡単に検証するため、ストレージはRDB to RDB
- **実務だと2000万件~n億件を処理する場合、S3 + Glue + GlueJob(PySpark)などのETL機構を検討する(予算と要件から検討)**。

#### 設計
- **使用技術**
    - ETLワーカー: Golang
    - DB: RDS for MySQL
    - インフラ(TODO): EventBridge, ECS Foragate, RDS, SecretManager

- **インフラ**
    - ECSタスクでGoのETLバッチを起動する
    - EventBridgeでスケジュール実行する

- **データ**
    - 重複排除のため、timestamp, device_type, event_typeでユニークにする

- **テーブル**
    - raw_records: rawデータ格納用
    - records: ETL後のデータ格納用
- **Extract**
    - データの抽出処理
        - source_db.recordsテーブルからデータを取得
- **Transform**
    - データの変換処理
        - バリデーション: 実装なし
        - 変換処理: messageを小文字→大文字に変換
- **Load**
    - DBへの接続はRDS　proxyのコネクションプール使用
    - N件ずつバルクインサート(検証する)
    - 冪等性を担保する

#### 技術的な工夫点
- **① OFFSETを使わずID範囲指定**
    - OFFSETはO(N)スキャンが遅延の原因
    - IDレンジ分割による範囲取得でスループットを向上
        - ExtractA: 1〜10000, ExtractB: 10001〜20000
    - 付随してID範囲を分けることによりLoaderの並列化が可能になった

- **② コネクションプールの活用**
    - DB/sql標準のSetMaxOpenConnsやSetMaxIdleConnsを活用しているとすれば、接続再利用効率が高い
    - ECSタスクとしてデプロイ後は RDS Proxyと併用でスループット向上
- **③ バルクインサートによる効率化**
    - 1万件ごとのバルクインサート
- **④ 明示的なトランザクション定義**
    - トランザクションをバルク単位に制御することで、ロールバック可能にする
    - 明示的にトランザクション定義することで、バルク単位でのコミットを行いスループットの向上
        - 明示的に定義しない場合、1INSERT毎にコミットされてしまうため...

- **⑤ 冪等性確保のためUpsertを使用**
    - 何度ETLを再実行しても、rawデータが変わっていない限り同じ結果になる
    - テーブルのユニーク制約で重複防止

- **⑥ 並列比率 (E:T:L = 4:4:2)**
    - 5,000件チャンク × 10,000件バルクの組み合わせ
        - E: 5000チャンク×4並列=20000レコード
        - T: 5000チャンク×4並列=20000レコード
        - L: 10000バルク×2並列=20000レコード
    - Loaderは3件以上にすると、トランザクション範囲の重複によるデッドロックが発生する可能性が高い
    - (5:5:1), (2:2:1), (8:8:4), (1:2:1)など様々な件数で検証
    -  E:T:L = 4:4:2が最もスループットが高く、エラー発生率も少なかった

#### 実施結果
**ローカルで実施して検証**

**結果:**
- 構成: OFFSET廃止、Loaderを2並列に変更
    - E:T:L = 4:4:2の並列構成
    - チャンク数: 5000件
    - バルク数: 10000件

    - スループット
        - 最速で500万件のデータを3分34秒でETL完了
        - 最遅で500万件を10分ほど
        - エラー件数0件
        - 22,624 records/sec(最速)
        - 8,333records/sec(最遅)

        - RDBへのI/Oが最大のボトルネック
        - バルクが多いほどスループットは高い(マシンの性能依存も大)

    - 単純計算のみだが、3分34秒×4= 13分ほどなので2000万件のETLが可能そう。
    - TODO: デプロイ後RDSと接続して性能検証
